{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Ruta al archivo CSV\n",
    "file_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/movies_dataset.csv\"\n",
    "\n",
    "\n",
    "# Cargar el CSV, especificando el parámetro 'low_memory=False' para evitar el DtypeWarning\n",
    "df = pd.read_csv(file_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maron.LAPTOP-UEJMOSD4\\AppData\\Local\\Temp\\ipykernel_238980\\3562817647.py:8: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo cargado correctamente.\n",
      "   adult                              belongs_to_collection    budget  \\\n",
      "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
      "1  False                                                NaN  65000000   \n",
      "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
      "3  False                                                NaN  16000000   \n",
      "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
      "\n",
      "                                              genres  \\\n",
      "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
      "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
      "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
      "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
      "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
      "\n",
      "                               homepage     id    imdb_id original_language  \\\n",
      "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
      "1                                   NaN   8844  tt0113497                en   \n",
      "2                                   NaN  15602  tt0113228                en   \n",
      "3                                   NaN  31357  tt0114885                en   \n",
      "4                                   NaN  11862  tt0113041                en   \n",
      "\n",
      "                original_title  \\\n",
      "0                    Toy Story   \n",
      "1                      Jumanji   \n",
      "2             Grumpier Old Men   \n",
      "3            Waiting to Exhale   \n",
      "4  Father of the Bride Part II   \n",
      "\n",
      "                                            overview  ... release_date  \\\n",
      "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
      "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
      "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
      "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
      "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
      "\n",
      "       revenue runtime                                   spoken_languages  \\\n",
      "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
      "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "\n",
      "     status                                            tagline  \\\n",
      "0  Released                                                NaN   \n",
      "1  Released          Roll the dice and unleash the excitement!   \n",
      "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
      "3  Released  Friends are the people who let you be yourself...   \n",
      "4  Released  Just When His World Is Back To Normal... He's ...   \n",
      "\n",
      "                         title  video vote_average vote_count  \n",
      "0                    Toy Story  False          7.7     5415.0  \n",
      "1                      Jumanji  False          6.9     2413.0  \n",
      "2             Grumpier Old Men  False          6.5       92.0  \n",
      "3            Waiting to Exhale  False          6.1       34.0  \n",
      "4  Father of the Bride Part II  False          5.7      173.0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Especifica la ruta del archivo\n",
    "file_path = r\"C:\\Users\\maron.LAPTOP-UEJMOSD4\\Desktop\\sistema de recomendacion\\movies_dataset.csv\"\n",
    "\n",
    "# Carga el CSV en un DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Archivo cargado correctamente.\")\n",
    "    print(df.head())  # Muestra las primeras filas del DataFrame\n",
    "except FileNotFoundError:\n",
    "    print(f\"El archivo en la ruta {file_path} no se encontró.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               belongs_to_collection\n",
      "0  {'id': 10194, 'name': 'Toy Story Collection', ...\n",
      "1                                                NaN\n",
      "2  {'id': 119050, 'name': 'Grumpy Old Men Collect...\n",
      "3                                                NaN\n",
      "4  {'id': 96871, 'name': 'Father of the Bride Col...\n"
     ]
    }
   ],
   "source": [
    "# Extraer la columna \"belongs_to_collection\" y crear un nuevo DataFrame\n",
    "df_collection = df[['belongs_to_collection']].copy()\n",
    "\n",
    "# Mostrar las primeras filas del nuevo DataFrame\n",
    "print(df_collection.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maron.LAPTOP-UEJMOSD4\\AppData\\Local\\Temp\\ipykernel_238980\\2646257262.py:5: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                            name\n",
      "0       10194.0            Toy Story Collection\n",
      "1           NaN                             NaN\n",
      "2      119050.0       Grumpy Old Men Collection\n",
      "3           NaN                             NaN\n",
      "4       96871.0  Father of the Bride Collection\n",
      "...         ...                             ...\n",
      "45461       NaN                             NaN\n",
      "45462       NaN                             NaN\n",
      "45463       NaN                             NaN\n",
      "45464       NaN                             NaN\n",
      "45465       NaN                             NaN\n",
      "\n",
      "[45466 rows x 2 columns]\n",
      "Nuevo archivo guardado en: C:\\Users\\maron.LAPTOP-UEJMOSD4\\Desktop\\sistema de recomendacion\\Movies\\belongs_to_collection.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV actualizado\n",
    "csv_path = r\"C:\\Users\\maron.LAPTOP-UEJMOSD4\\Desktop\\sistema de recomendacion\\Movies\\movies_dataset.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Asegurarnos de que la columna belongs_to_collection sea interpretada correctamente\n",
    "# Convertir las cadenas que representan diccionarios en objetos de Python\n",
    "def parse_collection(value):\n",
    "    if value == \"{}\" or pd.isna(value):  # Manejar \"{}\" y valores NaN\n",
    "        return None\n",
    "    try:\n",
    "        # Evaluar la cadena como un diccionario\n",
    "        return eval(value)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['belongs_to_collection'] = df['belongs_to_collection'].apply(parse_collection)\n",
    "\n",
    "# Limpiar y desanidar la columna belongs_to_collection\n",
    "def clean_collection(row):\n",
    "    if isinstance(row, dict):\n",
    "        return {key: row[key] for key in row if key not in ['poster_path', 'backdrop_path']}\n",
    "    return None\n",
    "\n",
    "df['belongs_to_collection'] = df['belongs_to_collection'].apply(clean_collection)\n",
    "\n",
    "# Desanidar la columna belongs_to_collection en un nuevo DataFrame\n",
    "df_collection_clean = pd.json_normalize(df['belongs_to_collection'])\n",
    "\n",
    "# Mostrar el nuevo DataFrame desanidado\n",
    "print(df_collection_clean)\n",
    "\n",
    "# Guardar el DataFrame desanidado como un nuevo CSV\n",
    "output_path = r\"C:\\Users\\maron.LAPTOP-UEJMOSD4\\Desktop\\sistema de recomendacion\\Movies\\belongs_to_collection.csv\"\n",
    "df_collection_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Nuevo archivo guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45466 entries, 0 to 45465\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      4491 non-null   float64\n",
      " 1   name    4491 non-null   object \n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 710.5+ KB\n",
      "None\n",
      "         id                            name\n",
      "0   10194.0            Toy Story Collection\n",
      "1       NaN                             NaN\n",
      "2  119050.0       Grumpy Old Men Collection\n",
      "3       NaN                             NaN\n",
      "4   96871.0  Father of the Bride Collection\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo generado\n",
    "csv_path = r\"C:\\Users\\maron.LAPTOP-UEJMOSD4\\Desktop\\sistema de recomendacion\\Movies\\belongs_to_collection.csv\"\n",
    "\n",
    "# Cargar el archivo CSV en un DataFrame\n",
    "df_collection_clean = pd.read_csv(csv_path)\n",
    "\n",
    "# Mostrar la información del DataFrame\n",
    "print(df_collection_clean.info())\n",
    "\n",
    "# Opcional: Mostrar las primeras filas para revisar el contenido\n",
    "print(df_collection_clean.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4491 entries, 0 to 45382\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      4491 non-null   int64 \n",
      " 1   name    4491 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 105.3+ KB\n",
      "None\n",
      "        id                            name\n",
      "0    10194            Toy Story Collection\n",
      "2   119050       Grumpy Old Men Collection\n",
      "4    96871  Father of the Bride Collection\n",
      "9      645           James Bond Collection\n",
      "12  117693                Balto Collection\n",
      "Archivo limpio guardado en: C:\\Users\\maron.LAPTOP-UEJMOSD4\\Desktop\\sistema de recomendacion\\Movies\\belongs_to_collection_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo generado\n",
    "csv_path = r\"C:\\Users\\maron.LAPTOP-UEJMOSD4\\Desktop\\sistema de recomendacion\\Movies\\belongs_to_collection.csv\"\n",
    "\n",
    "# Cargar el archivo CSV en un DataFrame\n",
    "df_collection_clean = pd.read_csv(csv_path)\n",
    "\n",
    "# Eliminar filas con valores nulos\n",
    "df_collection_clean = df_collection_clean.dropna()\n",
    "\n",
    "# Convertir la columna 'id' a tipo entero (int64)\n",
    "df_collection_clean['id'] = df_collection_clean['id'].astype('int64')\n",
    "\n",
    "# Mostrar información después de eliminar nulos y convertir la columna 'id'\n",
    "print(df_collection_clean.info())\n",
    "\n",
    "# Opcional: Mostrar las primeras filas para revisar el contenido\n",
    "print(df_collection_clean.head())\n",
    "\n",
    "# Guardar el DataFrame limpio y con 'id' como entero en un nuevo archivo CSV\n",
    "output_path = r\"C:\\Users\\maron.LAPTOP-UEJMOSD4\\Desktop\\sistema de recomendacion\\Movies\\belongs_to_collection_clean.csv\"\n",
    "df_collection_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Archivo limpio guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo ha sido guardado en: C:\\Users\\maron.LAPTOP-UEJMOSD4\\Desktop\\sistema de recomendacion\\Movies\\belongs_to_collection.csv\n"
     ]
    }
   ],
   "source": [
    "# Especificar la ruta para guardar el archivo\n",
    "output_path = r\"C:\\Users\\maron.LAPTOP-UEJMOSD4\\Desktop\\sistema de recomendacion\\Movies\\belongs_to_collection.csv\"\n",
    "\n",
    "# Guardar como archivo CSV\n",
    "df_collection_clean.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"El archivo ha sido guardado en: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              id                            name  \\\n",
      "0       10194.0            Toy Story Collection   \n",
      "1           NaN                             NaN   \n",
      "2      119050.0       Grumpy Old Men Collection   \n",
      "3           NaN                             NaN   \n",
      "4       96871.0  Father of the Bride Collection   \n",
      "...         ...                             ...   \n",
      "45461       NaN                             NaN   \n",
      "45462       NaN                             NaN   \n",
      "45463       NaN                             NaN   \n",
      "45464       NaN                             NaN   \n",
      "45465       NaN                             NaN   \n",
      "\n",
      "                            poster_path                     backdrop_path  \n",
      "0      /7G9915LfUQ2lVfwMEEhDsn3kT4B.jpg  /9FBwqcd9IRruEDUrTdcaafOMKUq.jpg  \n",
      "1                                   NaN                               NaN  \n",
      "2      /nLvUdqgPgm3F85NMCii9gVFUcet.jpg  /hypTnLot2z8wpFS7qwsQHW1uV8u.jpg  \n",
      "3                                   NaN                               NaN  \n",
      "4      /nts4iOmNnq7GNicycMJ9pSAn204.jpg  /7qwE57OVZmMJChBpLEbJEmzUydk.jpg  \n",
      "...                                 ...                               ...  \n",
      "45461                               NaN                               NaN  \n",
      "45462                               NaN                               NaN  \n",
      "45463                               NaN                               NaN  \n",
      "45464                               NaN                               NaN  \n",
      "45465                               NaN                               NaN  \n",
      "\n",
      "[45466 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar la columna que contiene los datos anidados\n",
    "column_name = 'belongs_to_collection'  # Cambia esto por el nombre real de la columna\n",
    "nested_col = df[column_name].copy()\n",
    "\n",
    "# Convertir los strings de la columna en diccionarios\n",
    "def parse_nested_data(row):\n",
    "    try:\n",
    "        return ast.literal_eval(row)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "\n",
    "nested_col = nested_col.apply(parse_nested_data)\n",
    "\n",
    "# Crear un nuevo DataFrame a partir de la columna desanidada\n",
    "df_nested = pd.json_normalize(nested_col)\n",
    "\n",
    "print(df_nested.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado guardado en: C:\\Users\\maron.LAPTOP-UEJMOSD4\\Desktop\\sistema de recomendacion\\Movies\\movida_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "#Eliminar las columnas 'poster_path' y 'backdrop_path'\n",
    "columns_to_drop = ['poster_path', 'backdrop_path']\n",
    "df_nested = df_nested.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Combinar el DataFrame original con el DataFrame desanidado (si es necesario)\n",
    "df = pd.concat([df, df_nested], axis=1)\n",
    "\n",
    "# Guardar el DataFrame actualizado en un nuevo archivo CSV\n",
    "output_file = r\"C:\\Users\\maron.LAPTOP-UEJMOSD4\\Desktop\\sistema de recomendacion\\Movies\\movida_cleaned.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Archivo procesado guardado en: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo original (ajustar si es necesario)\n",
    "csv_path = r\"C:\\Users\\maron.LAPTOP-UEJMOSD4\\Desktop\\sistema de recomendacion\\Movies\\movies_dataset.csv\"\n",
    "\n",
    "# Cargar el archivo CSV en un DataFrame\n",
    "df_movies = pd.read_csv(csv_path)\n",
    "\n",
    "# Revisar la columna production_companies antes de trabajar con ella\n",
    "print(df_movies['production_companies'].head())\n",
    "\n",
    "# Convertir la columna 'production_companies' de string a lista de diccionarios\n",
    "import ast\n",
    "df_movies['production_companies'] = df_movies['production_companies'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "\n",
    "# Crear un nuevo DataFrame desanidado para 'production_companies'\n",
    "df_production_companies = df_movies.explode('production_companies')  # Expandir listas en filas\n",
    "\n",
    "# Extraer los campos 'id' y 'name' de los diccionarios dentro de la columna\n",
    "df_production_companies_clean = pd.json_normalize(df_production_companies['production_companies'])\n",
    "\n",
    "# Agregar las columnas adicionales necesarias (por ejemplo, el id de la película, si aplica)\n",
    "df_production_companies_clean['movie_id'] = df_production_companies.index\n",
    "\n",
    "# Mostrar el DataFrame desanidado\n",
    "print(df_production_companies_clean.head())\n",
    "\n",
    "# Guardar el DataFrame desanidado en un nuevo archivo CSV\n",
    "output_path = r\"C:\\Users\\maron.LAPTOP-UEJMOSD4\\Desktop\\sistema de recomendacion\\Movies\\production_companies.csv\"\n",
    "df_production_companies_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Archivo desanidado guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                production_companies\n",
      "0     [{'name': 'Pixar Animation Studios', 'id': 3}]\n",
      "1  [{'name': 'TriStar Pictures', 'id': 559}, {'na...\n",
      "2  [{'name': 'Warner Bros.', 'id': 6194}, {'name'...\n",
      "3  [{'name': 'Twentieth Century Fox Film Corporat...\n",
      "4  [{'name': 'Sandollar Productions', 'id': 5842}...\n"
     ]
    }
   ],
   "source": [
    "# Extraer la columna \"belongs_to_collection\" y crear un nuevo DataFrame\n",
    "df_producction = df[['production_companies']].copy()\n",
    "\n",
    "# Mostrar las primeras filas del nuevo DataFrame\n",
    "print(df_producction.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        name       id\n",
      "0    Pixar Animation Studios      3.0\n",
      "1           TriStar Pictures    559.0\n",
      "2               Teitler Film   2550.0\n",
      "3  Interscope Communications  10201.0\n",
      "4               Warner Bros.   6194.0\n",
      "Archivo desanidado guardado en: C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/production_companies_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Convertir la columna 'production_companies' de string a lista de diccionarios\n",
    "df_producction['production_companies'] = df_producction['production_companies'].apply(\n",
    "    lambda x: ast.literal_eval(x) if pd.notnull(x) else []\n",
    ")\n",
    "\n",
    "# Desanidar la columna 'production_companies'\n",
    "df_production_clean = df_producction.explode('production_companies')  # Expandir listas en filas\n",
    "\n",
    "# Convertir los diccionarios a columnas\n",
    "df_production_clean = pd.json_normalize(df_production_clean['production_companies'])\n",
    "\n",
    "# Mostrar el DataFrame desanidado\n",
    "print(df_production_clean.head())\n",
    "\n",
    "# Guardar el DataFrame limpio en un archivo CSV\n",
    "output_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/production_companies_clean.csv\"\n",
    "df_production_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Archivo desanidado guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iso_3166_1                      name\n",
      "0         US  United States of America\n",
      "1         US  United States of America\n",
      "2         US  United States of America\n",
      "3         US  United States of America\n",
      "4         US  United States of America\n",
      "Archivo desanidado guardado en: C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/production_countries_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Ruta al archivo CSV\n",
    "file_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/movies_dataset.csv\"\n",
    "\n",
    "# Cargar el CSV, especificando el parámetro 'low_memory=False'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Extraer la columna \"production_countries\" y crear un nuevo DataFrame\n",
    "df_countries = df[['production_countries']].copy()\n",
    "\n",
    "# Convertir la columna 'production_countries' de string a lista de diccionarios\n",
    "df_countries['production_countries'] = df_countries['production_countries'].apply(\n",
    "    lambda x: ast.literal_eval(x) if pd.notnull(x) else []\n",
    ")\n",
    "\n",
    "# Desanidar la columna 'production_countries'\n",
    "df_countries_clean = df_countries.explode('production_countries')  # Expandir listas en filas\n",
    "\n",
    "# Convertir los diccionarios a columnas\n",
    "df_countries_clean = pd.json_normalize(df_countries_clean['production_countries'])\n",
    "\n",
    "# Mostrar el DataFrame desanidado\n",
    "print(df_countries_clean.head())\n",
    "\n",
    "# Guardar el DataFrame limpio en un archivo CSV\n",
    "output_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/production_countries_clean.csv\"\n",
    "df_countries_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Archivo desanidado guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m df_genres_clean \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(df_genres_exploded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Añadir el ID de la película al DataFrame limpio\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mdf_genres_clean\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovie_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m df_genres_exploded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Reorganizar las columnas para mejor legibilidad\u001b[39;00m\n\u001b[0;32m     28\u001b[0m df_genres_clean \u001b[38;5;241m=\u001b[39m df_genres_clean[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4517\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4530\u001b[0m     ):\n\u001b[0;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:5263\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Series):\n\u001b[0;32m   5262\u001b[0m         value \u001b[38;5;241m=\u001b[39m Series(value)\n\u001b[1;32m-> 5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reindex_for_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m   5266\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:12692\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  12688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m  12689\u001b[0m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[0;32m  12690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m  12691\u001b[0m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n\u001b[1;32m> 12692\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m  12694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m  12695\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible index of inserted column with frame index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  12696\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m  12697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reindexed_value, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:12687\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  12685\u001b[0m \u001b[38;5;66;03m# GH#4107\u001b[39;00m\n\u001b[0;32m  12686\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m> 12687\u001b[0m     reindexed_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m  12688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m  12689\u001b[0m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[0;32m  12690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m  12691\u001b[0m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:5153\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[1;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5136\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   5137\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m   5138\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5151\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5152\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m-> 5153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:5610\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   5609\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5611\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m   5612\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:5633\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5630\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   5632\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[1;32m-> 5633\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m   5635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5637\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[0;32m   5638\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   5639\u001b[0m     {axis: [new_index, indexer]},\n\u001b[0;32m   5640\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5641\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5642\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   5643\u001b[0m )\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4429\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   4426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle a non-unique multi-index!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m   4428\u001b[0m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[1;32m-> 4429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4431\u001b[0m     indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Ruta al archivo CSV\n",
    "file_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/movies_dataset.csv\"\n",
    "\n",
    "# Cargar el CSV, especificando el parámetro 'low_memory=False'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Extraer las columnas \"id\" y \"genres\" para crear un nuevo DataFrame\n",
    "df_genres = df[['id', 'genres']].copy()\n",
    "\n",
    "# Convertir la columna 'genres' de string a lista de diccionarios\n",
    "df_genres['genres'] = df_genres['genres'].apply(\n",
    "    lambda x: ast.literal_eval(x) if pd.notnull(x) else []\n",
    ")\n",
    "\n",
    "# Explosión de listas para desanidar los géneros\n",
    "df_genres_exploded = df_genres.explode('genres')  # Expandir listas en filas\n",
    "\n",
    "# Convertir los diccionarios en columnas\n",
    "df_genres_clean = pd.json_normalize(df_genres_exploded['genres'])\n",
    "\n",
    "# Añadir el ID de la película al DataFrame limpio\n",
    "df_genres_clean['movie_id'] = df_genres_exploded['id']\n",
    "\n",
    "# Reorganizar las columnas para mejor legibilidad\n",
    "df_genres_clean = df_genres_clean[['movie_id', 'id', 'name']]\n",
    "\n",
    "# Mostrar el DataFrame desanidado\n",
    "print(df_genres_clean.head())\n",
    "\n",
    "# Guardar el DataFrame limpio en un archivo CSV\n",
    "output_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/genres_clean.csv\"\n",
    "df_genres_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Archivo desanidado guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  movie_id       id       name\n",
      "0      862     16.0  Animation\n",
      "1      862     35.0     Comedy\n",
      "2      862  10751.0     Family\n",
      "3     8844     12.0  Adventure\n",
      "4     8844     14.0    Fantasy\n",
      "Archivo desanidado guardado en: C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/genres_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Ruta al archivo CSV\n",
    "file_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/movies_dataset.csv\"\n",
    "\n",
    "# Cargar el CSV, especificando el parámetro 'low_memory=False'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Extraer las columnas \"id\" y \"genres\" para crear un nuevo DataFrame\n",
    "df_genres = df[['id', 'genres']].copy()\n",
    "\n",
    "# Convertir la columna 'genres' de string a lista de diccionarios\n",
    "df_genres['genres'] = df_genres['genres'].apply(\n",
    "    lambda x: ast.literal_eval(x) if pd.notnull(x) else []\n",
    ")\n",
    "\n",
    "# Asegurarnos de que el índice sea único\n",
    "df_genres.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Explosión de listas para desanidar los géneros\n",
    "df_genres_exploded = df_genres.explode('genres')  # Expandir listas en filas\n",
    "\n",
    "# Convertir los diccionarios en columnas\n",
    "df_genres_clean = pd.json_normalize(df_genres_exploded['genres'])\n",
    "\n",
    "# Añadir el ID de la película al DataFrame limpio\n",
    "df_genres_clean['movie_id'] = df_genres_exploded['id'].values\n",
    "\n",
    "# Reorganizar las columnas para mejor legibilidad\n",
    "df_genres_clean = df_genres_clean[['movie_id', 'id', 'name']]\n",
    "\n",
    "# Mostrar el DataFrame desanidado\n",
    "print(df_genres_clean.head())\n",
    "\n",
    "# Guardar el DataFrame limpio en un archivo CSV\n",
    "output_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/genres_clean.csv\"\n",
    "df_genres_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Archivo desanidado guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  movie_id    genre_1  genre_2  genre_3 genre_4 genre_5 genre_6 genre_7  \\\n",
      "0      862  Animation   Comedy   Family     NaN     NaN     NaN     NaN   \n",
      "1     8844  Adventure  Fantasy   Family     NaN     NaN     NaN     NaN   \n",
      "2    15602    Romance   Comedy      NaN     NaN     NaN     NaN     NaN   \n",
      "3    31357     Comedy    Drama  Romance     NaN     NaN     NaN     NaN   \n",
      "4    11862     Comedy      NaN      NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "  genre_8  \n",
      "0     NaN  \n",
      "1     NaN  \n",
      "2     NaN  \n",
      "3     NaN  \n",
      "4     NaN  \n",
      "Archivo desanidado guardado en: C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/genres_expanded.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Ruta al archivo CSV\n",
    "file_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/movies_dataset.csv\"\n",
    "\n",
    "# Cargar el CSV, especificando el parámetro 'low_memory=False'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Extraer las columnas \"id\" y \"genres\" para crear un nuevo DataFrame\n",
    "df_genres = df[['id', 'genres']].copy()\n",
    "\n",
    "# Convertir la columna 'genres' de string a lista de diccionarios\n",
    "df_genres['genres'] = df_genres['genres'].apply(\n",
    "    lambda x: ast.literal_eval(x) if pd.notnull(x) else []\n",
    ")\n",
    "\n",
    "# Función para convertir la lista de géneros en columnas\n",
    "def expand_genres(row):\n",
    "    genres = row['genres']\n",
    "    genre_names = [genre['name'] for genre in genres]\n",
    "    return pd.Series(genre_names)\n",
    "\n",
    "# Aplicamos la función para expandir los géneros en columnas\n",
    "df_genres_expanded = df_genres.apply(expand_genres, axis=1)\n",
    "\n",
    "# Renombrar las columnas con nombres adecuados (genre_1, genre_2, ...)\n",
    "df_genres_expanded.columns = [f'genre_{i+1}' for i in range(df_genres_expanded.shape[1])]\n",
    "\n",
    "# Añadir el movie_id a la DataFrame expandido\n",
    "df_genres_expanded['movie_id'] = df_genres['id']\n",
    "\n",
    "# Reorganizar las columnas para que movie_id esté al principio\n",
    "df_genres_expanded = df_genres_expanded[['movie_id'] + [col for col in df_genres_expanded.columns if col != 'movie_id']]\n",
    "\n",
    "# Mostrar el DataFrame con géneros expandido\n",
    "print(df_genres_expanded.head())\n",
    "\n",
    "# Guardar el DataFrame expandido en un archivo CSV\n",
    "output_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/genres_expanded.csv\"\n",
    "df_genres_expanded.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Archivo desanidado guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo de géneros guardado en: C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/all_genres.csv\n",
      "Archivo de películas con géneros guardado en: C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/movies_with_genres.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Ruta al archivo CSV\n",
    "file_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/movies_dataset.csv\"\n",
    "\n",
    "# Cargar el CSV, especificando el parámetro 'low_memory=False'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Extraer las columnas \"id\" y \"genres\" para crear un nuevo DataFrame\n",
    "df_genres = df[['id', 'genres']].copy()\n",
    "\n",
    "# Convertir la columna 'genres' de string a lista de diccionarios\n",
    "df_genres['genres'] = df_genres['genres'].apply(\n",
    "    lambda x: ast.literal_eval(x) if pd.notnull(x) else []\n",
    ")\n",
    "\n",
    "# Crear una lista de todos los géneros únicos\n",
    "all_genres = []\n",
    "for genres_list in df_genres['genres']:\n",
    "    for genre in genres_list:\n",
    "        all_genres.append(genre)\n",
    "\n",
    "# Convertir la lista de géneros en un DataFrame y eliminar duplicados\n",
    "df_all_genres = pd.DataFrame(all_genres).drop_duplicates(subset=['id'])\n",
    "\n",
    "# Guardar el DataFrame de géneros en un CSV\n",
    "output_genres_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/all_genres.csv\"\n",
    "df_all_genres.to_csv(output_genres_path, index=False)\n",
    "\n",
    "print(f\"Archivo de géneros guardado en: {output_genres_path}\")\n",
    "\n",
    "# Ahora, crear una columna con las listas de ids de géneros para cada película\n",
    "df_genres['genre_ids'] = df_genres['genres'].apply(\n",
    "    lambda x: [genre['id'] for genre in x]\n",
    ")\n",
    "\n",
    "# Mantener solo las columnas relevantes\n",
    "df_movie_genres = df_genres[['id', 'genre_ids']]\n",
    "\n",
    "# Renombrar la columna 'id' a 'movie_id'\n",
    "df_movie_genres = df_movie_genres.rename(columns={'id': 'movie_id'})\n",
    "\n",
    "# Guardar el DataFrame de películas con sus géneros asociados en un CSV\n",
    "output_movies_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/movies_with_genres.csv\"\n",
    "df_movie_genres.to_csv(output_movies_path, index=False)\n",
    "\n",
    "print(f\"Archivo de películas con géneros guardado en: {output_movies_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo limpio guardado en: C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/movies_dataset_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo original de películas\n",
    "file_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/movies_dataset.csv\"\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Columnas a eliminar\n",
    "columns_to_drop = ['belongs_to_collection', 'genres', 'production_companies', 'production_countries']\n",
    "\n",
    "# Eliminar las columnas especificadas\n",
    "df_cleaned = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Renombrar la columna 'id' a 'movie_id'\n",
    "df_cleaned = df_cleaned.rename(columns={'id': 'movie_id'})\n",
    "\n",
    "# Guardar el DataFrame limpio en un nuevo archivo CSV\n",
    "output_cleaned_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/movies_dataset_cleaned.csv\"\n",
    "df_cleaned.to_csv(output_cleaned_path, index=False)\n",
    "\n",
    "print(f\"Archivo limpio guardado en: {output_cleaned_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo con cambios guardado en: C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/Movies/CSV/movies_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo original\n",
    "file_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/movies_dataset.csv\"\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Rellenar los valores nulos en 'revenue' y 'budget' con 0\n",
    "df['revenue'] = df['revenue'].fillna(0).astype(str)  # Convertir a str después de rellenar\n",
    "df['budget'] = df['budget'].fillna(0).astype(str)  # Convertir a str después de rellenar\n",
    "\n",
    "# Guardar el DataFrame con los cambios en el nuevo archivo CSV\n",
    "output_file_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/Movies/CSV/movies_dataset.csv\"\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Archivo con cambios guardado en: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo con columnas eliminadas guardado en: C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/Movies/CSV/movies_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo original\n",
    "file_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/movies_dataset.csv\"\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Eliminar las columnas \"belongs_to_collection\", \"genres\", \"production_companies\", \"production_countries\"\n",
    "columns_to_drop = [\"belongs_to_collection\", \"genres\", \"production_companies\", \"production_countries\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Guardar el DataFrame con los cambios en el nuevo archivo CSV\n",
    "output_file_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/Movies/CSV/movies_dataset.csv\"\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Archivo con columnas eliminadas guardado en: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  release_date\n",
      "0   1995-10-30\n",
      "1   1995-12-15\n",
      "2   1995-12-22\n",
      "3   1995-12-22\n",
      "4   1995-02-10\n",
      "Se encontraron fechas con formato incorrecto.\n",
      "adult                 object\n",
      "budget                object\n",
      "homepage              object\n",
      "id                    object\n",
      "imdb_id               object\n",
      "original_language     object\n",
      "original_title        object\n",
      "overview              object\n",
      "popularity            object\n",
      "poster_path           object\n",
      "release_date          object\n",
      "revenue              float64\n",
      "runtime              float64\n",
      "spoken_languages      object\n",
      "status                object\n",
      "tagline               object\n",
      "title                 object\n",
      "video                 object\n",
      "vote_average         float64\n",
      "vote_count           float64\n",
      "release_year         float64\n",
      "dtype: object\n",
      "Archivo actualizado con la columna 'release_year' y fechas corregidas guardado en: C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/Movies/CSV/movies_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo CSV\n",
    "file_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/Movies/CSV/movies_dataset.csv\"\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Mostrar las primeras filas para inspección\n",
    "print(df[['release_date']].head())\n",
    "\n",
    "# 1. Eliminar los valores nulos en la columna \"release_date\"\n",
    "df = df.dropna(subset=['release_date'])\n",
    "\n",
    "# 2. Verificar el formato de la fecha y convertir al formato \"AAAA-mm-dd\"\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "\n",
    "# Comprobar si hay alguna fecha mal formada (se convertiría a NaT)\n",
    "if df['release_date'].isnull().any():\n",
    "    print(\"Se encontraron fechas con formato incorrecto.\")\n",
    "\n",
    "# 3. Crear la columna \"release_year\" extrayendo el año de la fecha\n",
    "df['release_year'] = df['release_date'].dt.year\n",
    "\n",
    "# 4. Verificar el tipo de dato de \"release_date\" y convertirlo a tipo string si es necesario\n",
    "df['release_date'] = df['release_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Verificar los tipos de datos para asegurarnos que \"release_date\" es str y \"release_year\" es int\n",
    "print(df.dtypes)\n",
    "\n",
    "# Guardar los cambios en un nuevo archivo CSV\n",
    "output_file_path = r\"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/Movies/CSV/movies_dataset.csv\"\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Archivo actualizado con la columna 'release_year' y fechas corregidas guardado en: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                cast  \\\n",
      "0  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
      "1  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
      "\n",
      "                                                crew    id  \n",
      "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...   862  \n",
      "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...  8844  \n",
      "El archivo procesado se ha guardado en: C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast_processed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast  # Para interpretar las cadenas como listas/diccionarios de Python\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "file_path = r\"C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\credits.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Inspeccionar la estructura\n",
    "print(df.head(2))\n",
    "\n",
    "# Función para procesar la columna 'cast'\n",
    "def process_cast(cast_data):\n",
    "    try:\n",
    "        # Convertir la cadena en una lista de diccionarios\n",
    "        cast_list = ast.literal_eval(cast_data)\n",
    "        # Extraer campos relevantes\n",
    "        return [\n",
    "            {\n",
    "                \"name\": member.get(\"name\", None),\n",
    "                \"character\": member.get(\"character\", None),\n",
    "                \"gender\": member.get(\"gender\", None),\n",
    "            }\n",
    "            for member in cast_list\n",
    "        ]\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "# Aplicar la función a la columna 'cast'\n",
    "df[\"cast_processed\"] = df[\"cast\"].apply(process_cast)\n",
    "\n",
    "# Expandir la información procesada en un nuevo DataFrame\n",
    "cast_expanded = df.explode(\"cast_processed\")\n",
    "cast_expanded = pd.json_normalize(cast_expanded[\"cast_processed\"])\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo CSV\n",
    "output_file = r\"C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast_processed.csv\"\n",
    "cast_expanded.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"El archivo procesado se ha guardado en: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Aplicar la función a la columna 'cast'\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcast_processed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Expandir las listas procesadas en filas\u001b[39;00m\n\u001b[0;32m     32\u001b[0m cast_expanded \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcast_processed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 29\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Aplicar la función a la columna 'cast'\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcast_processed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mprocess_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Expandir las listas procesadas en filas\u001b[39;00m\n\u001b[0;32m     32\u001b[0m cast_expanded \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcast_processed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mprocess_cast\u001b[1;34m(cast_data)\u001b[0m\n\u001b[0;32m     12\u001b[0m     cast_list \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(cast_data)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Extraer campos relevantes\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     processed_data \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     15\u001b[0m         {\n\u001b[1;32m---> 16\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovie_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mrow\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m],  \u001b[38;5;66;03m# Incluimos el ID de la película para referencia\u001b[39;00m\n\u001b[0;32m     17\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: member\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     18\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharacter\u001b[39m\u001b[38;5;124m\"\u001b[39m: member\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharacter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m: member\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcast_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: member\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcast_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m         }\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m member \u001b[38;5;129;01min\u001b[39;00m cast_list\n\u001b[0;32m     23\u001b[0m     ]\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processed_data\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mSyntaxError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'row' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Cargar el archivo CSV original\n",
    "file_path = r\"C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\credits.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Función para procesar la columna 'cast'\n",
    "def process_cast(cast_data):\n",
    "    try:\n",
    "        # Convertir la cadena en una lista de diccionarios\n",
    "        cast_list = ast.literal_eval(cast_data)\n",
    "        # Extraer campos relevantes\n",
    "        processed_data = [\n",
    "            {\n",
    "                \"movie_id\": row[\"id\"],  # Incluimos el ID de la película para referencia\n",
    "                \"name\": member.get(\"name\", None),\n",
    "                \"character\": member.get(\"character\", None),\n",
    "                \"gender\": member.get(\"gender\", None),\n",
    "                \"cast_id\": member.get(\"cast_id\", None)\n",
    "            }\n",
    "            for member in cast_list\n",
    "        ]\n",
    "        return processed_data\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        return []\n",
    "\n",
    "# Aplicar la función a la columna 'cast'\n",
    "df[\"cast_processed\"] = df.apply(lambda row: process_cast(row[\"cast\"]), axis=1)\n",
    "\n",
    "# Expandir las listas procesadas en filas\n",
    "cast_expanded = df.explode(\"cast_processed\").reset_index(drop=True)\n",
    "\n",
    "# Normalizar los datos para convertir los diccionarios en columnas\n",
    "cast_normalized = pd.json_normalize(cast_expanded[\"cast_processed\"])\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo CSV\n",
    "output_file = r\"C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast.csv\"\n",
    "cast_normalized.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"El nuevo archivo procesado se ha guardado en: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo procesado con 'movie_id' se ha guardado en: C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Cargar el archivo CSV original\n",
    "file_path = r\"C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\credits.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Verificar si las columnas necesarias existen\n",
    "if 'id' not in df.columns or 'cast' not in df.columns:\n",
    "    raise ValueError(\"El archivo CSV debe contener las columnas 'id' y 'cast'.\")\n",
    "\n",
    "# Procesar la columna 'cast'\n",
    "def process_cast(row):\n",
    "    try:\n",
    "        # Convertir la cadena en una lista de diccionarios\n",
    "        cast_list = ast.literal_eval(row[\"cast\"])\n",
    "        # Extraer campos relevantes de cada miembro del reparto\n",
    "        processed_data = [\n",
    "            {\n",
    "                \"movie_id\": row[\"id\"],  # Incluimos el ID de la película\n",
    "                \"name\": member.get(\"name\", None),\n",
    "                \"character\": member.get(\"character\", None),\n",
    "                \"gender\": member.get(\"gender\", None),\n",
    "                \"cast_id\": member.get(\"cast_id\", None),\n",
    "            }\n",
    "            for member in cast_list\n",
    "        ]\n",
    "        return processed_data\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        return []\n",
    "\n",
    "# Crear una nueva columna procesada con datos del reparto\n",
    "df[\"cast_processed\"] = df.apply(process_cast, axis=1)\n",
    "\n",
    "# Expandir las listas procesadas en filas\n",
    "cast_expanded = df.explode(\"cast_processed\").reset_index(drop=True)\n",
    "\n",
    "# Normalizar los datos para convertir los diccionarios en columnas\n",
    "cast_normalized = pd.json_normalize(cast_expanded[\"cast_processed\"])\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo CSV\n",
    "output_file = r\"C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast.csv\"\n",
    "cast_normalized.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"El archivo procesado con 'movie_id' se ha guardado en: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo con la columna 'cast' se ha guardado en: C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast_anida.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo original\n",
    "file_path = r\"C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\credits.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Verificar si la columna 'cast' existe\n",
    "if 'cast' not in df.columns:\n",
    "    raise ValueError(\"El archivo CSV debe contener la columna 'cast'.\")\n",
    "\n",
    "# Crear un nuevo DataFrame con las columnas 'id' y 'cast'\n",
    "cast_df = df[['id', 'cast']]\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo CSV\n",
    "output_file = r\"C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast_anida.csv\"\n",
    "cast_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"El archivo con la columna 'cast' se ha guardado en: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo desanidado guardado en: C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast_desanidado.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Ruta del archivo\n",
    "input_file = r'C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast_anida.csv'\n",
    "output_file = r'C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast_desanidado.csv'\n",
    "\n",
    "# Leer el archivo CSV\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Función para procesar la columna 'cast'\n",
    "def process_cast(cast_data, movie_id):\n",
    "    try:\n",
    "        # Convertir el string de la columna 'cast' en una lista de diccionarios\n",
    "        cast_list = ast.literal_eval(cast_data)\n",
    "        \n",
    "        # Extraer datos relevantes\n",
    "        processed_data = [\n",
    "            {\n",
    "                \"movie_id\": movie_id,\n",
    "                \"cast_id\": member.get(\"cast_id\"),\n",
    "                \"character\": member.get(\"character\"),\n",
    "                \"credit_id\": member.get(\"credit_id\"),\n",
    "                \"gender\": member.get(\"gender\"),\n",
    "                \"id\": member.get(\"id\"),\n",
    "                \"name\": member.get(\"name\"),\n",
    "                \"order\": member.get(\"order\")\n",
    "            }\n",
    "            for member in cast_list\n",
    "        ]\n",
    "        return processed_data\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        return []\n",
    "\n",
    "# Expandir la columna 'cast'\n",
    "all_cast_data = []\n",
    "for _, row in df.iterrows():\n",
    "    movie_id = row['movie_id']\n",
    "    cast_data = row['cast']\n",
    "    all_cast_data.extend(process_cast(cast_data, movie_id))\n",
    "\n",
    "# Crear un nuevo DataFrame con los datos procesados\n",
    "desnested_df = pd.DataFrame(all_cast_data)\n",
    "\n",
    "# Guardar el DataFrame en un nuevo archivo CSV\n",
    "desnested_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Archivo desanidado guardado en: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros en 'cast_anida.csv': 562474\n",
      "Total de registros en 'cast_desanidado.csv': 562474\n",
      "Diferencia en el número de registros: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m name \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Revisar si el registro existe en el archivo original\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m original_cast \u001b[38;5;241m=\u001b[39m df_anida[\u001b[43mdf_anida\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m movie_id][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcast\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m original_cast\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     40\u001b[0m     datos_conservados \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Cargar los archivos\n",
    "file_anida = \"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/cast_anida.csv\"\n",
    "file_desanidado = \"C:/Users/USUARIO/Desktop/SOYhENRY/sistema de recomendacion/cast_desanidado.csv\"\n",
    "\n",
    "df_anida = pd.read_csv(file_anida)\n",
    "df_desanidado = pd.read_csv(file_desanidado)\n",
    "\n",
    "# Calcular el número total de registros en cast_anida\n",
    "total_registros_anida = 0\n",
    "\n",
    "for cast_data in df_anida['cast']:\n",
    "    try:\n",
    "        cast_list = ast.literal_eval(cast_data)\n",
    "        total_registros_anida += len(cast_list)\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        pass  # Ignorar errores de formato en la columna\n",
    "\n",
    "# Calcular el número total de registros en cast_desanidado\n",
    "total_registros_desanidado = len(df_desanidado)\n",
    "\n",
    "# Comparar los datos\n",
    "diferencia_registros = total_registros_desanidado - total_registros_anida\n",
    "\n",
    "print(\"Total de registros en 'cast_anida.csv':\", total_registros_anida)\n",
    "print(\"Total de registros en 'cast_desanidado.csv':\", total_registros_desanidado)\n",
    "print(\"Diferencia en el número de registros:\", diferencia_registros)\n",
    "\n",
    "# Verificar coincidencia de datos\n",
    "datos_conservados = True\n",
    "for _, row in df_desanidado.iterrows():\n",
    "    movie_id = row['movie_id']\n",
    "    cast_id = row['cast_id']\n",
    "    name = row['name']\n",
    "    # Revisar si el registro existe en el archivo original\n",
    "    original_cast = df_anida[df_anida['id'] == movie_id]['cast']\n",
    "    if original_cast.empty:\n",
    "        datos_conservados = False\n",
    "        print(f\"Registro no encontrado en cast_anida para movie_id: {movie_id}\")\n",
    "    else:\n",
    "        try:\n",
    "            cast_list = ast.literal_eval(original_cast.values[0])\n",
    "            if not any(member.get('cast_id') == cast_id and member.get('name') == name for member in cast_list):\n",
    "                datos_conservados = False\n",
    "                print(f\"Datos inconsistentes para movie_id: {movie_id}, cast_id: {cast_id}, name: {name}\")\n",
    "        except Exception as e:\n",
    "            datos_conservados = False\n",
    "            print(f\"Error procesando movie_id: {movie_id} - {e}\")\n",
    "\n",
    "if datos_conservados:\n",
    "    print(\"Todos los datos se conservaron correctamente.\")\n",
    "else:\n",
    "    print(\"Se encontraron inconsistencias en los datos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registro faltante: movie_id=11031, name=Tony Hendra\t\n",
      "Registro faltante: movie_id=56235, name=\tDouglas Hegdahl\n",
      "Registro faltante: movie_id=1923, name=Joseph L. Altruda\t\n",
      "Registro faltante: movie_id=39867, name=\tRobert Osth\n",
      "Registro faltante: movie_id=73059, name=​Ljubiša Samardžić\n",
      "Registro faltante: movie_id=14728, name=Beth Burvant\n",
      "Registro faltante: movie_id=8952, name=Beth Burvant\n",
      "Registro faltante: movie_id=32151, name=\tYip Chun\n",
      "Registro faltante: movie_id=125874, name=Frank Deacy\t... \tFather Joseph\n",
      "Registro faltante: movie_id=41387, name=\tYip Chun\n",
      "Registro faltante: movie_id=72711, name=\"Lil' Mikey\" Davis\n",
      "Registro faltante: movie_id=84342, name=Royce Da 5'9\"\n",
      "Registro faltante: movie_id=422906, name=William Edmondson\t\n",
      "Registro faltante: movie_id=90617, name=​Ljubiša Samardžić\n",
      "Registro faltante: movie_id=17082, name=\tCheung Chi-Sing\n",
      "Registro faltante: movie_id=82492, name=Josiah Patkotak \n",
      "Registro faltante: movie_id=319070, name=Tony Hendra\t\n",
      "Registro faltante: movie_id=133459, name=Madeleine Barwén Trollvik\t\n",
      "Registro faltante: movie_id=107287, name=Charo Soriano\t\n",
      "Registro faltante: movie_id=34449, name=​Ljubiša Samardžić\n",
      "Registro faltante: movie_id=86215, name=John Greer\t\n",
      "Registro faltante: movie_id=86271, name=James Carroll Pickett\t\n",
      "Registro faltante: movie_id=88348, name=James Carroll Pickett\t\n",
      "Registro faltante: movie_id=84994, name=Smokey Huff\t\n",
      "Registro faltante: movie_id=219335, name=Hillevi Lagerstam\t\n",
      "Registro faltante: movie_id=143355, name=​Ljubiša Samardžić\n",
      "Registro faltante: movie_id=48180, name=Lena Marie Johansson\t\n",
      "Registro faltante: movie_id=284154, name=​Ljubiša Samardžić\n",
      "Registro faltante: movie_id=60759, name=Kevin Bennett\t...\n",
      "Registro faltante: movie_id=388399, name=Cara Leroy O'Connell\t\n",
      "Registro faltante: movie_id=461088, name=هستی مهدوی‌فر\n",
      "Datos conservados: False\n",
      "Registros en cast_anida.csv: 45476\n",
      "Registros en cast_desanidado.csv: 562474\n",
      "Variación en el número de registros: 516998\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos\n",
    "path_anida = r'C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast_anida.csv'\n",
    "path_desanidado = r'C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast_desanidado.csv'\n",
    "\n",
    "df_anida = pd.read_csv(path_anida)\n",
    "df_desanidado = pd.read_csv(path_desanidado)\n",
    "\n",
    "# Verificar que cada registro en cast_desanidado esté presente en cast_anida\n",
    "datos_conservados = True\n",
    "\n",
    "for _, row in df_desanidado.iterrows():\n",
    "    movie_id = row['movie_id']\n",
    "    name = row['name']\n",
    "    \n",
    "    # Revisar si el registro existe en el archivo original\n",
    "    original_cast = df_anida[df_anida['movie_id'] == movie_id]['cast']\n",
    "    if original_cast.empty or name not in original_cast.values[0]:\n",
    "        datos_conservados = False\n",
    "        print(f\"Registro faltante: movie_id={movie_id}, name={name}\")\n",
    "\n",
    "# Calcular variación en el número de registros\n",
    "num_registros_anida = len(df_anida)\n",
    "num_registros_desanidado = len(df_desanidado)\n",
    "variacion = num_registros_desanidado - num_registros_anida\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Datos conservados: {datos_conservados}\")\n",
    "print(f\"Registros en cast_anida.csv: {num_registros_anida}\")\n",
    "print(f\"Registros en cast_desanidado.csv: {num_registros_desanidado}\")\n",
    "print(f\"Variación en el número de registros: {variacion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros faltantes añadidos: 31\n",
      "Archivo actualizado guardado en: C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast_desanidado_actualizado.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos\n",
    "path_anida = r'C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast_anida.csv'\n",
    "path_desanidado = r'C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast_desanidado.csv'\n",
    "\n",
    "df_anida = pd.read_csv(path_anida)\n",
    "df_desanidado = pd.read_csv(path_desanidado)\n",
    "\n",
    "# DataFrame para registros faltantes\n",
    "registros_faltantes = []\n",
    "\n",
    "for _, row in df_desanidado.iterrows():\n",
    "    movie_id = row['movie_id']\n",
    "    name = row['name']\n",
    "    \n",
    "    # Revisar si el registro existe en el archivo original\n",
    "    original_cast = df_anida[df_anida['movie_id'] == movie_id]['cast']\n",
    "    if original_cast.empty or name not in original_cast.values[0]:\n",
    "        registros_faltantes.append({\n",
    "            'movie_id': movie_id,\n",
    "            'cast_id': row.get('cast_id', None),\n",
    "            'character': row.get('character', None),\n",
    "            'credit_id': row.get('credit_id', None),\n",
    "            'gender': row.get('gender', None),\n",
    "            'id': row.get('id', None),\n",
    "            'name': name,\n",
    "            'order': row.get('order', None)\n",
    "        })\n",
    "\n",
    "# Crear un DataFrame con los registros faltantes\n",
    "df_faltantes = pd.DataFrame(registros_faltantes)\n",
    "\n",
    "# Concatenar con el archivo desanidado\n",
    "df_actualizado = pd.concat([df_desanidado, df_faltantes], ignore_index=True)\n",
    "\n",
    "# Guardar el archivo actualizado\n",
    "path_actualizado = r'C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\cast_desanidado_actualizado.csv'\n",
    "df_actualizado.to_csv(path_actualizado, index=False)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Registros faltantes añadidos: {len(df_faltantes)}\")\n",
    "print(f\"Archivo actualizado guardado en: {path_actualizado}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo crew.csv ha sido generado en: C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\crew.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo original\n",
    "path_credits = r'C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\credits.csv'\n",
    "\n",
    "# Ruta para guardar el archivo de salida\n",
    "path_crew = r'C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\crew.csv'\n",
    "\n",
    "# Cargar el archivo original\n",
    "df_credits = pd.read_csv(path_credits)\n",
    "\n",
    "# Extraer las columnas 'id' y 'crew'\n",
    "df_crew = df_credits[['id', 'crew']]\n",
    "\n",
    "# Guardar el nuevo archivo\n",
    "df_crew.to_csv(path_crew, index=False)\n",
    "\n",
    "print(f\"El archivo crew.csv ha sido generado en: {path_crew}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo crew_desanidado.csv ha sido generado en: C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\crew_desanidado.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Ruta del archivo crew.csv\n",
    "path_crew = r'C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\crew.csv'\n",
    "\n",
    "# Ruta para guardar el archivo desanidado\n",
    "path_crew_desanidado = r'C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\crew_desanidado.csv'\n",
    "\n",
    "# Cargar el archivo crew.csv\n",
    "df_crew = pd.read_csv(path_crew)\n",
    "\n",
    "# Renombrar la columna 'id' a 'movie_id' si no está ya renombrada\n",
    "if 'id' in df_crew.columns:\n",
    "    df_crew.rename(columns={'id': 'movie_id'}, inplace=True)\n",
    "\n",
    "# Función para procesar la columna 'crew'\n",
    "def process_crew(crew_data):\n",
    "    try:\n",
    "        # Convertir la columna crew de cadena a lista de diccionarios\n",
    "        crew_list = ast.literal_eval(crew_data)\n",
    "        # Extraer los campos relevantes\n",
    "        processed_data = [\n",
    "            {\n",
    "                'movie_id': movie_id,  # Incluimos el ID de la película para referencia\n",
    "                'credit_id': member.get('credit_id', None),\n",
    "                'department': member.get('department', None),\n",
    "                'gender': member.get('gender', None),\n",
    "                'id': member.get('id', None),\n",
    "                'job': member.get('job', None),\n",
    "                'name': member.get('name', None),\n",
    "            }\n",
    "            for member in crew_list\n",
    "        ]\n",
    "        return processed_data\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        return []\n",
    "\n",
    "# Aplicar la función a la columna 'crew' y desanidar\n",
    "rows = []\n",
    "for _, row in df_crew.iterrows():\n",
    "    movie_id = row['movie_id']\n",
    "    crew_data = row['crew']\n",
    "    processed_rows = process_crew(crew_data)\n",
    "    rows.extend(processed_rows)\n",
    "\n",
    "# Crear un nuevo DataFrame con los datos desanidados\n",
    "df_crew_desanidado = pd.DataFrame(rows)\n",
    "\n",
    "# Guardar el DataFrame resultante como archivo CSV\n",
    "df_crew_desanidado.to_csv(path_crew_desanidado, index=False)\n",
    "\n",
    "print(f\"El archivo crew_desanidado.csv ha sido generado en: {path_crew_desanidado}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros originales en 'crew.csv': 464314\n",
      "Registros en 'crew_desanidado.csv': 464314\n",
      "Todos los registros han sido procesados correctamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Rutas de los archivos\n",
    "path_crew = r'C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\crew.csv'\n",
    "path_crew_desanidado = r'C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\crew_desanidado.csv'\n",
    "\n",
    "# Cargar el archivo crew.csv\n",
    "df_crew = pd.read_csv(path_crew)\n",
    "\n",
    "# Renombrar la columna 'id' a 'movie_id' si no está ya renombrada\n",
    "if 'id' in df_crew.columns:\n",
    "    df_crew.rename(columns={'id': 'movie_id'}, inplace=True)\n",
    "\n",
    "# Función para procesar la columna 'crew'\n",
    "def process_crew(crew_data):\n",
    "    try:\n",
    "        # Convertir la columna crew de cadena a lista de diccionarios\n",
    "        crew_list = ast.literal_eval(crew_data)\n",
    "        # Extraer los campos relevantes\n",
    "        processed_data = [\n",
    "            {\n",
    "                'movie_id': movie_id,\n",
    "                'credit_id': member.get('credit_id', None),\n",
    "                'department': member.get('department', None),\n",
    "                'gender': member.get('gender', None),\n",
    "                'id': member.get('id', None),\n",
    "                'job': member.get('job', None),\n",
    "                'name': member.get('name', None),\n",
    "            }\n",
    "            for member in crew_list\n",
    "        ]\n",
    "        return processed_data\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        return []\n",
    "\n",
    "# Aplicar la función a la columna 'crew' y desanidar\n",
    "rows = []\n",
    "original_count = 0  # Contador de registros originales\n",
    "for _, row in df_crew.iterrows():\n",
    "    movie_id = row['movie_id']\n",
    "    crew_data = row['crew']\n",
    "    processed_rows = process_crew(crew_data)\n",
    "    rows.extend(processed_rows)\n",
    "    # Contar cuántos registros hay originalmente\n",
    "    try:\n",
    "        original_count += len(ast.literal_eval(crew_data))\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        pass\n",
    "\n",
    "# Crear un nuevo DataFrame con los datos desanidados\n",
    "df_crew_desanidado = pd.DataFrame(rows)\n",
    "\n",
    "# Guardar el DataFrame resultante como archivo CSV\n",
    "df_crew_desanidado.to_csv(path_crew_desanidado, index=False)\n",
    "\n",
    "# Comparar el número de registros\n",
    "desanidado_count = len(df_crew_desanidado)\n",
    "print(f\"Registros originales en 'crew.csv': {original_count}\")\n",
    "print(f\"Registros en 'crew_desanidado.csv': {desanidado_count}\")\n",
    "\n",
    "if original_count == desanidado_count:\n",
    "    print(\"Todos los registros han sido procesados correctamente.\")\n",
    "else:\n",
    "    print(\"Hay discrepancias en el número de registros. Verificar los datos procesados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_6304\\2708086072.py:7: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las siguientes columnas aún están presentes: ['video', 'imdb_id', 'adult', 'original_title', 'poster_path', 'homepage']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo\n",
    "file_path = r\"C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\Movies\\CSV\\movies_datasetc.csv\"\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Listar las columnas del archivo\n",
    "columnas_actuales = df.columns.tolist()\n",
    "\n",
    "# Columnas que deberían haber sido eliminadas\n",
    "columnas_a_eliminar = ['video', 'imdb_id', 'adult', 'original_title', 'poster_path', 'homepage']\n",
    "\n",
    "# Verificar si las columnas están presentes\n",
    "columnas_pendientes = [col for col in columnas_a_eliminar if col in columnas_actuales]\n",
    "\n",
    "# Resultados\n",
    "if columnas_pendientes:\n",
    "    print(f\"Las siguientes columnas aún están presentes: {columnas_pendientes}\")\n",
    "else:\n",
    "    print(\"Las columnas especificadas ya fueron eliminadas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_6304\\1165121996.py:7: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros antes: 45466\n",
      "Número de registros después: 45466\n",
      "Las columnas se eliminaron correctamente y se mantiene la cantidad de registros.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo\n",
    "file_path = r\"C:\\Users\\USUARIO\\Desktop\\SOYhENRY\\sistema de recomendacion\\Movies\\CSV\\movies_datasetc.csv\"\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Número de registros antes de eliminar columnas\n",
    "registros_antes = len(df)\n",
    "\n",
    "# Columnas a eliminar\n",
    "columnas_a_eliminar = ['video', 'imdb_id', 'adult', 'original_title', 'poster_path', 'homepage']\n",
    "\n",
    "# Eliminar columnas\n",
    "df = df.drop(columns=columnas_a_eliminar, errors='ignore')\n",
    "\n",
    "# Guardar el DataFrame actualizado en el mismo archivo\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Cargar nuevamente para verificar cambios\n",
    "df_actualizado = pd.read_csv(file_path)\n",
    "\n",
    "# Verificar que se mantenga la cantidad de registros\n",
    "registros_despues = len(df_actualizado)\n",
    "\n",
    "# Resultados\n",
    "print(f\"Número de registros antes: {registros_antes}\")\n",
    "print(f\"Número de registros después: {registros_despues}\")\n",
    "\n",
    "if registros_antes == registros_despues:\n",
    "    print(\"Las columnas se eliminaron correctamente y se mantiene la cantidad de registros.\")\n",
    "else:\n",
    "    print(\"Hubo un cambio inesperado en la cantidad de registros.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
